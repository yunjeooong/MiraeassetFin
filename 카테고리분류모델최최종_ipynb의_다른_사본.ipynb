{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunjeooong/MiraeassetFin/blob/main/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EC%B5%9C%EC%B5%9C%EC%A2%85_ipynb%EC%9D%98_%EB%8B%A4%EB%A5%B8_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sreiuM3FuoWx",
        "outputId": "0de53425-9306-41ff-9566-3457efd9d966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24FuU-LKEpIk"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE30NEKQuzvH",
        "outputId": "72ed7217-d9cc-4df8-8310-06877a6f2d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.3.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.23.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.7.21)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww7igrCguZP9",
        "outputId": "fa66eaf8-e0af-471b-df7d-99914d6724d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from konlpy.tag import Okt\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Is4MOg6OHSL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9Yqweh7wJ0S"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH6NfaeGNk9A",
        "outputId": "4e53a619-11e6-48a7-bf7c-53b0c1fca445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 로드\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "print(\"데이터 로드\")\n",
        "art_df = pd.read_excel('/content/preprocessed_article_df.xlsx', index_col=0)\n",
        "art_df.dropna(subset=['title', 'processed_text', 'section'], inplace=True)\n",
        "art_df['section'] = art_df['section'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-bf2_mENwPA",
        "outputId": "8de74858-4b96-4fd0-dd11-02730c54b4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 확인\n",
            "section\n",
            "4    243\n",
            "2    230\n",
            "1    184\n",
            "0    128\n",
            "3     94\n",
            "5     35\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 데이터 확인\n",
        "print(\"데이터 확인\")\n",
        "print(art_df['section'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpjVcGxWNucE",
        "outputId": "04493619-d6ba-463f-840d-71bef4ee5af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 분할\n",
            "클래스 분포 확인\n",
            "section\n",
            "4    194\n",
            "2    184\n",
            "1    147\n",
            "0    103\n",
            "3     75\n",
            "5     28\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분할\n",
        "print(\"데이터 분할\")\n",
        "train_df, test_df = train_test_split(art_df, test_size=0.2, random_state=42, stratify=art_df['section'])\n",
        "\n",
        "# 클래스 분포 확인\n",
        "print(\"클래스 분포 확인\")\n",
        "print(train_df['section'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEEUxDPeDlcT",
        "outputId": "842d7ed6-9624-433f-9f47-4eb40f950f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7jTHpo65L3i",
        "outputId": "4ffcd313-e304-4925-94dc-d8efb4923bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.7.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfQ8RoK8u9CP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from googletrans import Translator\n",
        "from konlpy.tag import Okt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4FtQ3g4vhiv"
      },
      "outputs": [],
      "source": [
        "okt = Okt()\n",
        "translator = Translator()\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for l in syn.lemmas():\n",
        "            synonyms.add(l.name())\n",
        "    return list(synonyms)\n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "    new_words = words.copy()\n",
        "    random_word_list = list(set([word for word in words if len(get_synonyms(word)) > 0]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if len(synonyms) >= 1:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "    return new_words\n",
        "\n",
        "def random_deletion(words, p):\n",
        "    if len(words) == 1:\n",
        "        return words\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        r = random.uniform(0, 1)\n",
        "        if r > p:\n",
        "            new_words.append(word)\n",
        "    if len(new_words) == 0:\n",
        "        rand_int = random.randint(0, len(words)-1)\n",
        "        return [words[rand_int]]\n",
        "    return new_words\n",
        "\n",
        "def random_swap(words, n):\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "        if len(new_words) >= 2:\n",
        "            idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
        "            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
        "    return new_words\n",
        "\n",
        "def back_translation(text):\n",
        "    try:\n",
        "        en_text = translator.translate(text, src='ko', dest='en').text\n",
        "        return translator.translate(en_text, src='en', dest='ko').text\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "def change_ending(text):\n",
        "    # 간단한 어미 변형 (존댓말 <-> 반말)\n",
        "    endings = {\n",
        "        '합니다': '해요',\n",
        "        '습니다': '어요',\n",
        "        '었습니다': '었어요',\n",
        "        '니다': '어요'\n",
        "    }\n",
        "    for end, replacement in endings.items():\n",
        "        if text.endswith(end):\n",
        "            return text[:-len(end)] + replacement\n",
        "    return text\n",
        "\n",
        "def augment(text, num_aug=4):\n",
        "    words = okt.morphs(text)\n",
        "    augmented_texts = []\n",
        "\n",
        "    for _ in range(num_aug):\n",
        "        aug_type = random.randint(0, 4)\n",
        "\n",
        "        if aug_type == 0:  # 동의어 대체\n",
        "            a_words = synonym_replacement(words, n=int(len(words)*0.1))\n",
        "        elif aug_type == 1:  # 무작위 삭제\n",
        "            a_words = random_deletion(words, p=0.1)\n",
        "        elif aug_type == 2:  # 무작위 순서 변경\n",
        "            a_words = random_swap(words, n=int(len(words)*0.1))\n",
        "        elif aug_type == 3:  # 백트랜슬레이션\n",
        "            a_words = okt.morphs(back_translation(text))\n",
        "        else:  # 어미 변형\n",
        "            a_words = okt.morphs(change_ending(text))\n",
        "\n",
        "        augmented_texts.append(' '.join(a_words))\n",
        "\n",
        "    return augmented_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXGaAGY-N8YT",
        "outputId": "9b0b71d3-6116-4985-93c2-14d215b3025d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "언더샘플링 후 클래스 분포 확인\n",
            "section\n",
            "4    970\n",
            "2    920\n",
            "1    735\n",
            "0    515\n",
            "3    375\n",
            "5    308\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 데이터 증강 수행\n",
        "augmented_texts = []\n",
        "augmented_labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    if row['section'] == 5:\n",
        "        augmented_texts.append(row['processed_text'])\n",
        "        augmented_labels.append(row['section'])\n",
        "        augmented_texts.extend(augment(row['processed_text'], num_aug=10))  # 증강 비율 조절\n",
        "        augmented_labels.extend([row['section']] * 10)\n",
        "    else:\n",
        "        augmented_texts.append(row['processed_text'])\n",
        "        augmented_labels.append(row['section'])\n",
        "        augmented_texts.extend(augment(row['processed_text']))\n",
        "        augmented_labels.extend([row['section']] * 4)\n",
        "\n",
        "augmented_df = pd.DataFrame({'processed_text': augmented_texts, 'section': augmented_labels})\n",
        "\n",
        "# 언더샘플링 제거\n",
        "balanced_df = augmented_df\n",
        "\n",
        "# 언더샘플링 후 클래스 분포 확인\n",
        "print(\"언더샘플링 후 클래스 분포 확인\")\n",
        "print(balanced_df['section'].value_counts())\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_counts = balanced_df['section'].value_counts().sort_index()\n",
        "total_samples = sum(class_counts)\n",
        "class_weights = [total_samples/class_counts[i] for i in range(len(class_counts))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV28x5t606ND",
        "outputId": "71bdcf04-20c2-4ea3-9de1-0675eb42ad61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         processed_text  section\n",
            "0     파리 연합뉴스 김도훈 기자 현지 시간 프랑스 파리 사우스 파리 아레나 유빈 코치 이...        4\n",
            "1     파리 연합뉴스 김도훈 기자 현지 시간 프랑스 파리 사우스 파리 아레나 유빈 코치 이...        4\n",
            "2     파리 연합뉴스 김도훈 기자 현지 시간 프랑스 파리 사우스 파리 아레나 유빈 코치 이...        4\n",
            "3     파리 연합뉴스 김도훈 있다 현지 시간 프랑스 파리 사우스 파리 아레나 유빈 코치 이...        4\n",
            "4     파리 연합뉴스 김도훈 기자 현지 시간 프랑스 파리 사우스 파리 아레나 유빈 코치 이...        4\n",
            "...                                                 ...      ...\n",
            "3818  미국 재무부 시간 북한 탄도 미사일 군사위성 개발 지원 중국 기업 곳 중국인 명 새...        4\n",
            "3819  미국 재무부 시간 북한 탄도 미사일 군사위성 개발 지원 중국 기업 곳 중국인 명 새...        4\n",
            "3820  미국 재무부 시간 북한 탄도 미사일 군사위성 개발 지원 중국 기업 곳 중국인 명 새...        4\n",
            "3821  미국 재무부 시간 북한 탄도 미사일 군사위성 개발 지원 기업 곳 중국인 명 새롭다 ...        4\n",
            "3822  미국 재무부 확산 북한 탄도 미사일 군사위성 개발 등 중국 기업 곳 해당 명 산 제...        4\n",
            "\n",
            "[3823 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(balanced_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_woGveaaujQh"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 및 데이터로더 정의\n",
        "# Dataset 클래스 정의\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 데이터로더 생성 함수 정의\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = NewsDataset(\n",
        "        texts=df.processed_text.to_numpy(),\n",
        "        labels=df.section.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGiCtORGHXm"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = NewsDataset(\n",
        "        texts=df.processed_text.to_numpy(),\n",
        "        labels=df.section.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=8\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93vc9RGEunWD"
      },
      "outputs": [],
      "source": [
        "# 학습 및 평가 함수 정의\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples, accumulation_steps=4):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for i, d in enumerate(tqdm(data_loader)):\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        labels = d[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item() * accumulation_steps)\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in tqdm(data_loader):\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            labels = d[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbts8G34xXbL"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련 및 평가 함수\n",
        "def train_model(train_loader, test_loader, model_name, num_epochs=5, batch_size=16, patience=2):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(set(balanced_df['section'])))\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)  # L2 정규화 추가\n",
        "    total_steps = len(train_loader) * num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    epochs_no_improve = 0\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        train_acc, train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler, len(train_loader.dataset))\n",
        "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "        val_acc, val_loss = eval_model(model, test_loader, loss_fn, device, len(test_loader.dataset))\n",
        "        print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "        if val_acc > best_accuracy:\n",
        "            best_accuracy = val_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                early_stop = True\n",
        "                print(\"Early stopping\")\n",
        "\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziCGMKawydj-"
      },
      "outputs": [],
      "source": [
        "# 앙상블 예측 함수\n",
        "def ensemble_predict_weighted(models, tokenizers, test_df, device, max_len=256, batch_size=8):\n",
        "    all_predictions = []\n",
        "    for model, tokenizer in zip(models, tokenizers):\n",
        "        test_data_loader = create_data_loader(test_df, tokenizer, max_len, batch_size)\n",
        "        model = model.eval()\n",
        "        predictions = []\n",
        "        with torch.no_grad():\n",
        "            for d in tqdm(test_data_loader):\n",
        "                input_ids = d[\"input_ids\"].to(device)\n",
        "                attention_mask = d[\"attention_mask\"].to(device)\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                predictions.extend(torch.softmax(outputs.logits, dim=1).cpu().numpy())\n",
        "        all_predictions.append(predictions)\n",
        "\n",
        "    ensemble_preds = np.mean(all_predictions, axis=0)\n",
        "    return np.argmax(ensemble_preds, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGwmvFIOzfwn",
        "outputId": "34e6279a-313c-42fa-c375-6d6f0a387858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 메모리 해제\n",
            "CUDA 정보\n",
            "CUDA available: True\n",
            "CUDA version: 12.1\n",
            "Training klue/roberta-base...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [01:22<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 1.3101216817750092 accuracy 0.5550614700496992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.7478949700792631 accuracy 0.7650273224043715\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [01:22<00:00,  2.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.7731921804998709 accuracy 0.7664138111430813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.7111943612496058 accuracy 0.7978142076502732\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [01:22<00:00,  2.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.5865336151240261 accuracy 0.8200366204551399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.6522307582199574 accuracy 0.8087431693989071\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [01:21<00:00,  2.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.4758961187465171 accuracy 0.8624117185456447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.6969431390364965 accuracy 0.7759562841530054\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [01:22<00:00,  2.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.4369581973172381 accuracy 0.8621501438660737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:01<00:00,  6.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.8113092333078384 accuracy 0.7540983606557377\n",
            "Early stopping\n",
            "Training klue/roberta-large...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [04:29<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 1.177391071449264 accuracy 0.5702328014648181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:05<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.6953309712310632 accuracy 0.7759562841530054\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [04:29<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.6845080481538214 accuracy 0.7802772691603452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:05<00:00,  2.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.7294838589926561 accuracy 0.7704918032786885\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [04:29<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.4938543404464193 accuracy 0.8388699973842532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:05<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.6259440618256727 accuracy 0.7814207650273224\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [04:29<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.40090143037609227 accuracy 0.8561339262359403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:05<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.7979899160563946 accuracy 0.7431693989071039\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 239/239 [04:29<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.34227998471316184 accuracy 0.8854302903478942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:05<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss 0.9625139124691486 accuracy 0.7377049180327869\n",
            "Early stopping\n",
            "앙상블 예측 실행\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:03<00:00,  6.84it/s]\n",
            "100%|██████████| 23/23 [00:09<00:00,  2.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy: 0.7650273224043715\n",
            "Ensemble F1 Score: 0.6925417795995291\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"GPU 메모리 해제\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"CUDA 정보\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "# 모델 및 데이터로더 설정\n",
        "model_names = ['klue/roberta-base', 'klue/roberta-large']\n",
        "num_epochs = 10\n",
        "batch_size = 16\n",
        "max_len = 128\n",
        "\n",
        "trained_models = []\n",
        "tokenizers = []\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"Training {model_name}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)  # 정확한 repo_id 사용\n",
        "    train_loader = create_data_loader(balanced_df, tokenizer, max_len, batch_size)\n",
        "    test_loader = create_data_loader(test_df, tokenizer, max_len, batch_size)\n",
        "    model = train_model(train_loader, test_loader, model_name, num_epochs, batch_size)\n",
        "    trained_models.append(model)\n",
        "    tokenizers.append(tokenizer)\n",
        "\n",
        "print(\"앙상블 예측 실행\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ensemble_preds = ensemble_predict_weighted(trained_models, tokenizers, test_df, device)\n",
        "\n",
        "# 결과 평가\n",
        "accuracy = accuracy_score(test_df.section, ensemble_preds)\n",
        "f1 = f1_score(test_df.section, ensemble_preds, average='macro')\n",
        "\n",
        "print(f'Ensemble Accuracy: {accuracy}')\n",
        "print(f'Ensemble F1 Score: {f1}')\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "cm = confusion_matrix(test_df.section, ensemble_preds)\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NnG6x3HJTM-",
        "outputId": "56d767c1-0bcc-4937-aaa3-207683ce2a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "기사: 원주시, 취약층 여름나기 점검 완료\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 사회\n",
            "\n",
            "기사: 유엔 “가자 인도주의 구역 대피령에 하루 새 15만명 탈출”\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 세계\n",
            "\n",
            "기사: 野, 교사 업무 ‘수업·연구’에 한정… 행정직원들 반발\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 사회\n",
            "\n",
            "기사: 독일 기후단체 '접착제 시위' 공항 3시간 마비\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 세계\n",
            "\n",
            "기사: 北 오물풍선에 대통령실도 뚫려… 軍, 대북전광판 재설치 할수도\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 정치\n",
            "\n",
            "기사: [Biz & Now] 농심, 파리에 신라면 팝업스토어 오픈\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 경제\n",
            "\n",
            "기사: 위메프 피해자 본사 항의…새벽 3시 일부 환불\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 사회\n",
            "\n",
            "기사: 평창군, 2024 평창더위사냥축제 준비 한창\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 사회\n",
            "\n",
            "기사: 이재명 \"탄핵, 국민이 결정할 사안…대통령 되면 개헌하려 했다\"\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 정치\n",
            "\n",
            "기사: 김민기 발인…‘아침이슬’과 함께 옛 학전에 마지막 인사\n",
            "예측된 섹션: 세계\n",
            "실제 섹션: 생활/문화\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sect_dic = {0: \"정치\", 1: \"경제\", 2: \"사회\", 3: \"생활/문화\", 4: \"세계\", 5: \"IT/과학\"}\n",
        "\n",
        "for i in range(10):  # 처음 10개 예측 결과 출력\n",
        "    print(f\"기사: {test_df.iloc[i].title}\")\n",
        "    print(f\"예측된 섹션: {sect_dic[ensemble_preds[i]]}\")\n",
        "    print(f\"실제 섹션: {sect_dic[test_df.section.iloc[i]]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx1kT2V60bRZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJiy2KatifI",
        "outputId": "efbf486f-5ea0-4732-ed07-2d412caadca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 메모리 초기화 완료\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def gpu_memory_reset():\n",
        "    # 현재 GPU 장치 설정\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # GPU 캐시 초기화\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Python의 garbage collector 호출\n",
        "    gc.collect()\n",
        "\n",
        "    # PyTorch CUDA 캐시 초기화\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "\n",
        "# GPU 메모리 초기화 함수 호출\n",
        "gpu_memory_reset()\n",
        "\n",
        "print(\"GPU 메모리 초기화 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYVOP1Zz3iXm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 새로운 데이터 파일 로드\n",
        "new_data_path = '/content/naver_news_content_20240722.xlsx'\n",
        "new_data_df = pd.read_excel(new_data_path)\n",
        "\n",
        "# Combine the title and content for prediction\n",
        "new_data_df['text'] = new_data_df['뉴스제목'] + ' ' + new_data_df['본문']\n",
        "new_data_df = new_data_df[['뉴스제목', '본문', 'text']]  # Include 뉴스제목 and 본\n",
        "\n",
        "# 디바이스 설정 (GPU 사용 가능 여부 확인)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpbDWcO03llY",
        "outputId": "34d1ed1d-5d22-4a63-e27f-d85080dc9702"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 모델 이름 정의\n",
        "model_names = ['klue/roberta-base', 'klue/roberta-large']\n",
        "trained_models = []\n",
        "tokenizers = []\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "for model_name in model_names:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "    model = model.to(device)\n",
        "    trained_models.append(model)\n",
        "    tokenizers.append(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVGxl63y3oTy"
      },
      "outputs": [],
      "source": [
        "# 새로운 데이터에 대한 데이터셋 클래스 정의\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIVc3WS23sI_"
      },
      "outputs": [],
      "source": [
        "# 새로운 데이터를 위한 데이터 로더 생성 함수\n",
        "def create_new_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = NewsDataset(\n",
        "        texts=df['text'].to_numpy(),  # 데이터프레임에서 텍스트 열 사용\n",
        "        labels=[0]*len(df),  # 더미 라벨 사용\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "    return DataLoader(ds, batch_size=batch_size, num_workers=8)  #cpu 8대인 가상 공간에서 진행 중\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBUJ97MH3zJx"
      },
      "outputs": [],
      "source": [
        "# 새로운 데이터를 데이터 로더에 로드\n",
        "new_data_loaders = [create_new_data_loader(new_data_df, tokenizer, max_len=128, batch_size=16) for tokenizer in tokenizers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_3f2SlO31Zx"
      },
      "outputs": [],
      "source": [
        "# 예측 수행 함수\n",
        "def predict(models, data_loaders, device):\n",
        "    all_predictions = []\n",
        "    for model, data_loader in zip(models, data_loaders):\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        with torch.no_grad():\n",
        "            for d in data_loader:\n",
        "                input_ids = d[\"input_ids\"].to(device)\n",
        "                attention_mask = d[\"attention_mask\"].to(device)\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                predictions.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
        "        all_predictions.append(predictions)\n",
        "    return all_predictions\n",
        "\n",
        "# 예측 결과 얻기\n",
        "all_preds = predict(trained_models, new_data_loaders, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xanDjmaW38LY"
      },
      "outputs": [],
      "source": [
        "# 예측 결과 얻기\n",
        "all_preds = predict(trained_models, new_data_loaders, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ltahP-J4AHk"
      },
      "outputs": [],
      "source": [
        "# 예측 결과 앙상블\n",
        "from scipy.stats import mode\n",
        "ensemble_preds = mode(all_preds, axis=0)[0].flatten()\n",
        "new_data_df['predicted_label'] = ensemble_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWd7QmW94FOR"
      },
      "outputs": [],
      "source": [
        "# 라벨을 섹션 이름으로 매핑\n",
        "sect_dic = {0: \"정치\", 1: \"경제\", 2: \"사회\", 3: \"생활/문화\", 4: \"세계\", 5: \"IT/과학\"}\n",
        "new_data_df['predicted_section'] = new_data_df['predicted_label'].map(sect_dic)\n",
        "\n",
        "# 라벨링된 데이터를 엑셀 파일로 저장\n",
        "output_path = '/content/labeled_news_data.xlsx'\n",
        "new_data_df.to_excel(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvsi0v268kZ3",
        "outputId": "eadea532-ec06-44c1-de71-8837ffd87746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 경제 data to /content/labeled_news_data/labeled_news_data_경제.xlsx\n",
            "Saved 생활/문화 data to /content/labeled_news_data/labeled_news_data_생활_문화.xlsx\n",
            "/content/labeled_news_data/labeled_news_data_생활_문화.xlsx\n",
            "/content/labeled_news_data/labeled_news_data_경제.xlsx\n",
            "/content/labeled_news_data/.ipynb_checkpoints\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# 라벨링된 데이터 파일 로드\n",
        "labeled_data_path = '/content/labeled_news_data.xlsx'\n",
        "labeled_data_df = pd.read_excel(labeled_data_path)\n",
        "\n",
        "# 저장할 디렉토리 경로 설정\n",
        "output_dir = '/content/labeled_news_data/'\n",
        "\n",
        "# 디렉토리가 존재하지 않으면 생성\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def safe_filename(filename):\n",
        "    # 파일 이름에서 안전하지 않은 문자를 제거\n",
        "    return re.sub(r'[^a-zA-Z0-9가-힣]', '_', filename)\n",
        "\n",
        "for section in sections:\n",
        "    section_df = labeled_data_df[labeled_data_df['predicted_section'] == section]\n",
        "    safe_section = safe_filename(section)\n",
        "    section_filename = os.path.join(output_dir, f'labeled_news_data_{safe_section}.xlsx')\n",
        "    section_df[['뉴스제목', '본문', 'predicted_section']].to_excel(section_filename, index=False)  # Include the required columns\n",
        "    print(f'Saved {section} data to {section_filename}')\n",
        "# 저장된 파일 리스트 출력\n",
        "saved_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir)]\n",
        "for file in saved_files:\n",
        "    print(file)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}